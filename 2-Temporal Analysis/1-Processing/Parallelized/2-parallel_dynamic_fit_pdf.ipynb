{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset $X, Y$ each having size $n$ and a fitting function $f$, we define our fit error measure as -\n",
    "\n",
    "$$J = \\sum_{i=1}^{n} (y_i - f(x_i))^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_error(y, f):\n",
    "    return np.sum((y-f)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting function 1, Gaussian - \n",
    "\n",
    "$$ p(z)= \\frac{A}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(z-\\mu)^2}{2 \\sigma^2}}$$\n",
    "\n",
    "Which we want to obey the same normalization as the numerical PDF -\n",
    "\n",
    "$$ \\int_{-\\infty}^{\\infty} p(z) dz = \\sum_{i = 1}^{n} w_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_func_1(Z, A, mu, sigma):\n",
    "    \n",
    "    P = (A/np.sqrt(2*np.pi*sigma**2))*np.exp(-((Z-mu)**2/(2*sigma**2)))\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting function 2, normalized, piece-wise gaussian + power-law given by - \n",
    "\n",
    "$$ p(z)=  \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\frac{A}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(z-\\mu)^2}{2 \\sigma^2}} : z < z_T \\\\\n",
    "      B e^{- \\alpha z} : z \\ge z_T \\\\\n",
    "\\end{array} \n",
    "\\right. $$\n",
    "\n",
    "Enforcing continuity at $z = z_T$ yields -\n",
    "\n",
    "$$ B = \\frac{Ae^{\\alpha z_T}}{\\sqrt{2 \\pi \\sigma^2}} e^{- \\frac{(z_T - \\mu)^2}{2 \\sigma^2}} $$\n",
    "\n",
    "Further, enforcing normalization identical to the numerical PDF, we get -\n",
    "\n",
    "$$A = \\frac{\\sum_{i = 1}^{n} w_i}{\\frac{1}{2}\\left( erf \\left( \\frac{z_T - \\mu}{\\sqrt{2} \\sigma} \\right) \\right) + \\frac{1}{\\alpha \\sqrt{2 \\pi \\sigma^2}} e^{- \\frac{(z_T - \\mu)^2}{2 \\sigma^2}}} $$\n",
    "\n",
    "Thus, the normalized PDF is -\n",
    "\n",
    "$$ p(z)=  \\frac{A}{\\sqrt{2 \\pi \\sigma^2}} \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      e^{-\\frac{(z-\\mu)^2}{2 \\sigma^2}} : z < z_T \\\\\n",
    "      e^{-\\frac{(z_T-\\mu)^2}{2 \\sigma^2}} \\cdot e^{- \\alpha(z-z_T)} : z \\ge z_T \\\\\n",
    "\\end{array} \n",
    "\\right. $$\n",
    "\n",
    "Which obeys the same normalization as the numerical PDF -\n",
    "\n",
    "$$ \\int_{-\\infty}^{\\infty} p(z) dz = \\sum_{i = 1}^{n} w_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_func_2(Z, A, mu, sigma, alpha, z_T):\n",
    "    \n",
    "    B = (A*np.exp(alpha*z_T))/np.sqrt(2*np.pi*sigma**2)*np.exp(-(z_T-mu)**2/(2*sigma**2))\n",
    "    \n",
    "    Z_1 = Z[np.where(Z <= z_T)]\n",
    "    Z_2 = Z[np.where(Z > z_T)]\n",
    "    \n",
    "    P_1 = (A/np.sqrt(2*np.pi*sigma**2))*np.exp(-((Z_1 - mu)**2/(2*sigma**2)))\n",
    "    P_2 = B*np.exp(-alpha*Z_2)\n",
    "\n",
    "    P = np.concatenate([P_1, P_2])\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing fitted PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_PDF(centers, heights):\n",
    "            \n",
    "    fit = np.zeros(len(centers))\n",
    "    fit_err = 0\n",
    "    fit_params = np.zeros(5)\n",
    "\n",
    "    # Information about the peak in the numerical PDF\n",
    "    peak_ind = np.where(heights == np.max(heights))[0][0]\n",
    "    peak_height = np.max(heights)\n",
    "\n",
    "    # mu is where the numerical PDF peaks\n",
    "    mu = centers[peak_ind]\n",
    "\n",
    "    # Estimating sigma using FWHM\n",
    "    sigma = 0\n",
    "\n",
    "    for i in range(0, peak_ind):\n",
    "        if(heights[i] >= peak_height/2):\n",
    "            sigma = (mu - centers[i])/np.sqrt(2*np.log(2))\n",
    "            break\n",
    "\n",
    "    # Estimating A accordingly, by using the peak value at mu\n",
    "    A = np.sqrt(2*np.pi*sigma**2)*peak_height\n",
    "    \n",
    "    # First fit a Gaussian\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        guess_params = np.array([A, mu, sigma])\n",
    "\n",
    "        fit_params, fit_covar = optimize.curve_fit(fit_func_1, centers, heights, p0=guess_params, method = 'dogbox')\n",
    "        fit = fit_func_1(centers, *fit_params)\n",
    "        fit_err = fit_error(heights, fit)\n",
    "        fit_params = np.concatenate([fit_params, np.array([float('nan'), float('nan')])])\n",
    "\n",
    "        # See if an exponential decay tail exists and is a better fit\n",
    "\n",
    "        for i in range(peak_ind, len(centers)):\n",
    "\n",
    "            v_T = centers[i] \n",
    "            init_height = heights[i]\n",
    "\n",
    "            # Estimating alpha using half-life decay\n",
    "            alpha = 0\n",
    "\n",
    "            for j in range(i+1, len(centers)):\n",
    "                if(heights[j] <= init_height/2):\n",
    "                    alpha = np.log(2)/(centers[j]-v_T)\n",
    "                    break\n",
    "\n",
    "            curr_guess_params = np.array([A, mu, sigma, alpha])\n",
    "\n",
    "            curr_fit_params, curr_fit_covar = optimize.curve_fit(\n",
    "                        lambda centers, A, mu, sigma, alpha: fit_func_2(centers, A, mu, sigma, alpha, v_T)\n",
    "                            , centers, heights, p0=curr_guess_params)\n",
    "\n",
    "            curr_fit = fit_func_2(centers, *curr_fit_params, v_T)\n",
    "            curr_err = fit_error(heights, curr_fit)\n",
    "\n",
    "            if(curr_err < fit_err):\n",
    "                fit = curr_fit\n",
    "                fit_err = curr_err\n",
    "                fit_params = np.concatenate([curr_fit_params, np.array([v_T])])\n",
    "\n",
    "    except:        \n",
    "        \n",
    "        pass\n",
    "\n",
    "    return fit, fit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_snap(info):\n",
    "    \n",
    "    snap_dict = info[0]\n",
    "    metals = info[1]\n",
    "    spath_metals = info[2]\n",
    "    q = info[3]\n",
    "\n",
    "    snap = snap_dict['snap']\n",
    "    redshift = snap_dict['redshift']\n",
    "        \n",
    "    try:\n",
    "\n",
    "        A = {}\n",
    "        mu = {}\n",
    "        sigma = {}\n",
    "        alpha = {}\n",
    "        z_T = {}\n",
    "\n",
    "        for m in metals:\n",
    "\n",
    "            num_df = pd.read_csv(spath_metals[m] +'data/num/' + str(snap) + '-num_' + m + '_data.csv')\n",
    "\n",
    "            centers = np.array(num_df['abundance'].to_list())\n",
    "\n",
    "            heights = np.array(num_df['num_val'].to_list())\n",
    "\n",
    "            mass_norm = np.max(heights)\n",
    "\n",
    "            heights /= mass_norm\n",
    "\n",
    "            # Compute the fitted PDF\n",
    "\n",
    "            fit, fit_params = fit_PDF(centers, heights)\n",
    "\n",
    "            # Rescaling range to achieve desired normalization\n",
    "\n",
    "            heights *= mass_norm\n",
    "            fit *= mass_norm\n",
    "            fit_params[0] *= mass_norm\n",
    "\n",
    "            A[m] = fit_params[0]\n",
    "            mu[m] = fit_params[1]\n",
    "            sigma[m] = fit_params[2]\n",
    "            alpha[m] = fit_params[3]\n",
    "            z_T[m] = fit_params[4]\n",
    "\n",
    "            datafile =  str(snap) + '-fit_' + m + '_data' + '.csv'\n",
    "\n",
    "            fit_dict = {'abundance': centers, 'fit_val': fit}\n",
    "            fit_df = pd.DataFrame(fit_dict)\n",
    "            fit_df.to_csv(spath_metals[m] + 'data/fit/' + datafile, index = False)\n",
    "\n",
    "        q.put({'snap_dict': snap_dict, 'A': A, 'mu': mu, 'sigma': sigma, 'alpha': alpha, 'z_T': z_T})\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        for m in metals:\n",
    "            \n",
    "            datafile =  'fit_{}_params.csv'.format(m)\n",
    "            fit_df = pd.read_csv(spath_metals[m] + 'data/fit/' + datafile)\n",
    "            fit_df = fit_df[fit_df.snap != snap]\n",
    "            fit_df.to_csv(spath_metals[m] + 'data/fit/' + datafile, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter simulation directory path: /Users/thepoetoftwilight/Documents/CASSI2020/CASSI2020-Code+Results/Results/m11b_res2100_cr_heating_fix/\n"
     ]
    }
   ],
   "source": [
    "# Specifying simulation directory and the directory to save results in\n",
    "wdir = str(input('Enter simulation directory path: '))\n",
    "\n",
    "# Specifying a snapshot for temporal analysis\n",
    "sdir = wdir + 'temporal_analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rendered indices\n",
    "\n",
    "rendered_df = pd.read_csv(sdir + 'rendered_snap_stats.csv')\n",
    "snap_dicts = rendered_df.to_dict(orient = 'records')\n",
    "\n",
    "# Get rendered metals\n",
    "\n",
    "metal_df = pd.read_csv((sdir + 'metal_list.csv'))\n",
    "metals = metal_df['metals'].to_list()\n",
    "\n",
    "# Create a list of paths for all metals\n",
    "spath_metals = {}\n",
    "\n",
    "for m in metals:\n",
    "    spath_metals[m] = sdir + m + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to start:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in multiply\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in multiply\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in multiply\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in multiply\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  if __name__ == '__main__':\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     snap      redshift       time     halo_mass  SFR@10Myr  SFR@100Myr  \\\n",
      "0      79  4.384615e+00   1.420917  5.721844e+09   0.031797    0.017922   \n",
      "1      80  4.338983e+00   1.439067  5.736586e+09   0.020477    0.020473   \n",
      "2      81  4.294117e+00   1.457291  5.714834e+09   0.006320    0.021094   \n",
      "3      82  4.250000e+00   1.475588  5.691378e+09   0.017575    0.017569   \n",
      "4      83  4.206611e+00   1.493956  5.652333e+09   0.001056    0.016594   \n",
      "..    ...           ...        ...           ...        ...         ...   \n",
      "511   596  6.373059e-04  13.789874  4.589969e+10   0.000000    0.000000   \n",
      "512   597  4.779283e-04  13.792092  4.590174e+10   0.000000    0.000000   \n",
      "513   598  3.186015e-04  13.794310  4.590417e+10   0.000000    0.000000   \n",
      "514   599  1.592253e-04  13.796529  4.590615e+10   0.000000    0.000000   \n",
      "515   600  4.440892e-16  13.798747  4.590833e+10   0.000000    0.000000   \n",
      "\n",
      "     SFR@1000Myr  velocity_mass  velocity_vol  velocity_rms_mass  ...  \\\n",
      "0       0.012866      82.506874    266.860168          91.279007  ...   \n",
      "1       0.013106      82.371468    267.070435          91.193314  ...   \n",
      "2       0.013148      81.910751    266.864166          90.679047  ...   \n",
      "3       0.013430      81.494301    266.659210          90.085899  ...   \n",
      "4       0.013431      81.105713    265.322052          89.625076  ...   \n",
      "..           ...            ...           ...                ...  ...   \n",
      "511     0.000614     112.105820    364.759033         140.360703  ...   \n",
      "512     0.000614     112.122864    364.818695         140.384995  ...   \n",
      "513     0.000614     112.140213    364.882202         140.410233  ...   \n",
      "514     0.000614     112.157608    364.945618         140.435364  ...   \n",
      "515     0.000614     112.175308    365.008148         140.460571  ...   \n",
      "\n",
      "     thermal_mass  thermal_vol  thermal_rms_mass  thermal_rms_vol  \\\n",
      "0       21.905174     6.870636         24.517139        10.273147   \n",
      "1       22.035023     6.832050         24.525425        10.245096   \n",
      "2       22.126060     6.793265         24.431179        10.217735   \n",
      "3       22.226440     6.753987         24.494307        10.187324   \n",
      "4       22.305977     6.737504         24.440325        10.180159   \n",
      "..            ...          ...               ...              ...   \n",
      "511     18.332230    20.445974         20.833406        69.178253   \n",
      "512     18.331409    20.450462         20.832376        69.185150   \n",
      "513     18.330818    20.454906         20.831684        69.191475   \n",
      "514     18.330091    20.459379         20.830799        69.197861   \n",
      "515     18.329296    20.463850         20.829756        69.204239   \n",
      "\n",
      "     thermal_spread  mach_number_mass  mach_number_vol  mach_number_rms_mass  \\\n",
      "0         10.977655          5.959786       251.493637              7.753571   \n",
      "1         10.742341          5.917894       254.252060              7.715159   \n",
      "2         10.338654          5.860090       256.560059              7.659449   \n",
      "3         10.267788          5.801325       258.663422              7.602383   \n",
      "4          9.971587          5.752675       260.954803              7.549119   \n",
      "..              ...               ...              ...                   ...   \n",
      "511        9.894421         11.677969       395.152924             18.609222   \n",
      "512        9.893707         11.680314       395.235626             18.613239   \n",
      "513        9.893479         11.682770       395.326324             18.617579   \n",
      "514        9.892910         11.685188       395.414490             18.621820   \n",
      "515        9.892152         11.687638       395.502655             18.626081   \n",
      "\n",
      "     mach_number_rms_vol  mach_number_spread  \n",
      "0             448.679047            4.957952  \n",
      "1             451.682312            4.948231  \n",
      "2             454.151978            4.930465  \n",
      "3             456.084473            4.911567  \n",
      "4             459.699982            4.886679  \n",
      "..                   ...                 ...  \n",
      "511           700.315369           14.489406  \n",
      "512           700.456116           14.492665  \n",
      "513           700.610046           14.496255  \n",
      "514           700.760986           14.499756  \n",
      "515           700.909546           14.503238  \n",
      "\n",
      "[516 rows x 27 columns]\n",
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    n_proc = multiprocessing.cpu_count()\n",
    "    \n",
    "    print(\"About to start:\")\n",
    "    \n",
    "    manager = multiprocessing.Manager()\n",
    "    q = manager.Queue()\n",
    "\n",
    "    with Pool(processes = n_proc) as pool:\n",
    "\n",
    "        pool.map(fit_snap, [(snap_dict, metals, spath_metals, q) for snap_dict in snap_dicts])\n",
    "    \n",
    "    info_dicts = []\n",
    "    \n",
    "    while not q.empty():\n",
    "        info_dicts.append(q.get())\n",
    "      \n",
    "    fitted_dicts = []\n",
    "    A_dicts = []\n",
    "    mu_dicts = []\n",
    "    sigma_dicts = []\n",
    "    alpha_dicts = []\n",
    "    z_T_dicts = []\n",
    "    \n",
    "    for info_dict in info_dicts:\n",
    "        \n",
    "        fitted_dicts.append(info_dict['snap_dict'])\n",
    "        A_dicts.append(info_dict['A'])\n",
    "        mu_dicts.append(info_dict['mu'])\n",
    "        sigma_dicts.append(info_dict['sigma'])\n",
    "        alpha_dicts.append(info_dict['alpha'])\n",
    "        z_T_dicts.append(info_dict['z_T'])\n",
    "        \n",
    "    num_fitted_snaps = len(fitted_dicts)\n",
    "        \n",
    "    fitted_indices = []\n",
    "    redshifts = []\n",
    "    times = []\n",
    "\n",
    "    halo_masses = []\n",
    "\n",
    "    SFRs_10 = []\n",
    "    SFRs_100 = []\n",
    "    SFRs_1000 = []\n",
    "\n",
    "    velocities_mass = []\n",
    "    velocities_vol = []\n",
    "    velocities_rms_mass = []\n",
    "    velocities_rms_vol = []\n",
    "    velocities_spread = []\n",
    "\n",
    "    sounds_mass = []\n",
    "    sounds_vol = []\n",
    "    sounds_rms_mass = []\n",
    "    sounds_rms_vol = []\n",
    "    sounds_spread = []\n",
    "\n",
    "    thermals_mass = []\n",
    "    thermals_vol = []\n",
    "    thermals_rms_mass = []\n",
    "    thermals_rms_vol = []\n",
    "    thermals_spread = []\n",
    "\n",
    "    mach_numbers_mass = []\n",
    "    mach_numbers_vol = []\n",
    "    mach_numbers_rms_mass = []\n",
    "    mach_numbers_rms_vol = []\n",
    "    mach_numbers_spread = []\n",
    "\n",
    "    As = {}\n",
    "    mus = {}\n",
    "    sigmas = {}\n",
    "    alphas = {}\n",
    "    z_Ts = {}   \n",
    "    \n",
    "    for m in metals:\n",
    "        As[m] = []\n",
    "        mus[m] = []\n",
    "        sigmas[m] = []\n",
    "        alphas[m] = []\n",
    "        z_Ts[m] = []\n",
    "\n",
    "    for i in range(0, num_fitted_snaps):\n",
    "        \n",
    "        fitted_dict = fitted_dicts[i]\n",
    "        A_dict = A_dicts[i]\n",
    "        mu_dict = mu_dicts[i]\n",
    "        sigma_dict = sigma_dicts[i]\n",
    "        alpha_dict = alpha_dicts[i]\n",
    "        z_T_dict = alpha_dicts[i]\n",
    "        \n",
    "        fitted_indices.append(fitted_dict['snap'])\n",
    "        \n",
    "        redshifts.append(fitted_dict['redshift'])\n",
    "        times.append(fitted_dict['time'])\n",
    "        \n",
    "        halo_masses.append(fitted_dict['halo_mass'])\n",
    "        \n",
    "        SFRs_10.append(fitted_dict['SFR@10Myr'])\n",
    "        SFRs_100.append(fitted_dict['SFR@100Myr'])\n",
    "        SFRs_1000.append(fitted_dict['SFR@1000Myr'])\n",
    "\n",
    "        velocities_mass.append(fitted_dict['velocity_mass'])\n",
    "        velocities_vol.append(fitted_dict['velocity_vol'])\n",
    "        velocities_rms_mass.append(fitted_dict['velocity_rms_mass'])\n",
    "        velocities_rms_vol.append(fitted_dict['velocity_rms_vol'])\n",
    "        velocities_spread.append(fitted_dict['velocity_spread'])\n",
    "\n",
    "        sounds_mass.append(fitted_dict['sound_mass'])\n",
    "        sounds_vol.append(fitted_dict['sound_vol'])\n",
    "        sounds_rms_mass.append(fitted_dict['sound_rms_mass'])\n",
    "        sounds_rms_vol.append(fitted_dict['sound_rms_vol'])\n",
    "        sounds_spread.append(fitted_dict['sound_spread'])\n",
    "\n",
    "        thermals_mass.append(fitted_dict['thermal_mass'])\n",
    "        thermals_vol.append(fitted_dict['thermal_vol'])\n",
    "        thermals_rms_mass.append(fitted_dict['thermal_rms_mass'])\n",
    "        thermals_rms_vol.append(fitted_dict['thermal_rms_vol'])\n",
    "        thermals_spread.append(fitted_dict['thermal_spread'])\n",
    "\n",
    "        mach_numbers_mass.append(fitted_dict['mach_number_mass'])\n",
    "        mach_numbers_vol.append(fitted_dict['mach_number_vol'])\n",
    "        mach_numbers_rms_mass.append(fitted_dict['mach_number_rms_mass'])\n",
    "        mach_numbers_rms_vol.append(fitted_dict['mach_number_rms_vol'])\n",
    "        mach_numbers_spread.append(fitted_dict['mach_number_spread'])\n",
    "        \n",
    "        for m in metals:\n",
    "            \n",
    "            As[m].append(A_dict[m])\n",
    "            mus[m].append(mu_dict[m])\n",
    "            sigmas[m].append(sigma_dict[m])\n",
    "            alphas[m].append(alpha_dict[m])\n",
    "            z_Ts[m].append(z_T_dict[m])\n",
    "            \n",
    "    fitted_stats_dict = {'snap': fitted_indices,  'redshift': redshifts, 'time': times, \n",
    "                           'halo_mass': halo_masses,\n",
    "                           'SFR@10Myr': SFRs_10, 'SFR@100Myr': SFRs_100, 'SFR@1000Myr': SFRs_1000,\n",
    "                           'velocity_mass': velocities_mass, 'velocity_vol': velocities_vol, \n",
    "                           'velocity_rms_mass': velocities_rms_mass, 'velocity_rms_vol': velocities_rms_vol, \n",
    "                           'velocity_spread': velocities_spread,\n",
    "                           'sound_mass': sounds_mass, 'sound_vol': sounds_vol,\n",
    "                           'sound_rms_mass': sounds_rms_mass, 'sound_rms_vol': sounds_rms_vol,\n",
    "                           'sound_spread': sounds_spread,\n",
    "                           'thermal_mass': thermals_mass, 'thermal_vol': thermals_vol,\n",
    "                           'thermal_rms_mass': thermals_rms_mass, 'thermal_rms_vol': thermals_rms_vol,\n",
    "                           'thermal_spread': thermals_spread,\n",
    "                           'mach_number_mass': mach_numbers_mass, 'mach_number_vol': mach_numbers_vol,\n",
    "                           'mach_number_rms_mass': mach_numbers_rms_mass, \n",
    "                           'mach_number_rms_vol': mach_numbers_rms_vol, \n",
    "                           'mach_number_spread': mach_numbers_spread}\n",
    "\n",
    "    fitted_stats_df = pd.DataFrame(fitted_stats_dict)\n",
    "    fitted_stats_df = fitted_stats_df.sort_values(by = 'snap')\n",
    "    fitted_stats_df = fitted_stats_df.reset_index(drop = True)\n",
    "    fitted_stats_df.to_csv(sdir + 'fitted_snap_stats.csv', index = False)\n",
    "\n",
    "    print(fitted_stats_df)\n",
    "    print()\n",
    "\n",
    "    for m in metals:\n",
    "        param_df_init = pd.read_csv(spath_metals[m] + 'data/fit/fit_{}_params.csv'.format(m))\n",
    "        param_dict_append = {'A': As[m], 'mu': mus[m], 'sigma': sigmas[m], \n",
    "                      'alpha': alphas[m], 'z_T': z_Ts[m]}\n",
    "        param_df_append = pd.DataFrame(param_dict_append)\n",
    "        param_df = pd.concat([param_df_init, param_df_append], axis = 1)\n",
    "        param_df.to_csv(spath_metals[m] + 'data/fit/fit_{}_params.csv'.format(m), index = False)\n",
    "        \n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
