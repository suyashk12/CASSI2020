{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset $X, Y$ each having size $n$ and a fitting function $f$, we define our fit error measure as -\n",
    "\n",
    "$$J = \\sum_{i=1}^{n} (y_i - f(x_i))^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_error(y, f):\n",
    "    return np.sum((y-f)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting function 1, Gaussian - \n",
    "\n",
    "$$ p(z)= \\frac{A}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(z-\\mu)^2}{2 \\sigma^2}}$$\n",
    "\n",
    "Which we want to obey the same normalization as the numerical PDF -\n",
    "\n",
    "$$ \\int_{-\\infty}^{\\infty} p(z) dz = \\sum_{i = 1}^{n} w_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_func_1(Z, A, sigma):\n",
    "    \n",
    "    P = (A/np.sqrt(2*np.pi*sigma**2))*np.exp(-Z**2/(2*sigma**2))\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting function 2, normalized, exponential deca7 - \n",
    "\n",
    "$$ p(z)=  B e^{- \\alpha z} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_func_2(Z, B, alpha):\n",
    "    \n",
    "    P = B*np.exp(-alpha*Z)\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing fitted PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_PDF(centers, heights):\n",
    "    \n",
    "    # Information about the peak in the numerical PDF\n",
    "    peak_height = np.max(heights)\n",
    "    peak_ind = np.where(heights == peak_height)[0][0]\n",
    "    \n",
    "    # mu is where the numerical PDF peaks\n",
    "    mu = centers[peak_ind]\n",
    " \n",
    "    # Recentering so that peak is at z = 0\n",
    "    del_centers = centers - mu\n",
    "    gauss_centers = del_centers[0:peak_ind+1]\n",
    "    gauss_heights = heights[0:peak_ind+1]\n",
    "                \n",
    "    fit = np.zeros(len(centers))\n",
    "    fit_err = np.inf\n",
    "    fit_params = np.zeros(5)\n",
    "    \n",
    "    for i in range(0, len(fit_params)):\n",
    "        fit_params[i] = float('nan')\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Estimating sigma using FWHM\n",
    "        sigma = 0\n",
    "\n",
    "        for i in range(0, len(gauss_centers)):\n",
    "            if(heights[i] >= peak_height/2):\n",
    "                sigma = (-gauss_centers[i])/np.sqrt(2*np.log(2))\n",
    "                break\n",
    "\n",
    "        # Estimating A accordingly, by using the peak height\n",
    "        A = np.sqrt(2*np.pi*sigma**2)*peak_height\n",
    "\n",
    "        # First fit a Gaussian\n",
    "\n",
    "        guess_gauss_params = np.array([A, sigma])\n",
    "        \n",
    "        gauss_bounds = ([0, 0], [np.max(heights), np.max(np.abs(del_centers))])\n",
    "\n",
    "        fit_gauss_params, fit_gauss_covar = optimize.curve_fit(fit_func_1, gauss_centers, gauss_heights,\n",
    "                                                               p0 = guess_gauss_params, \n",
    "                                                               bounds = gauss_bounds, method = 'trf')\n",
    "\n",
    "                \n",
    "        fit_params[0] = fit_gauss_params[0]\n",
    "        fit_params[1] = mu\n",
    "        fit_params[2] = fit_gauss_params[1]\n",
    "\n",
    "        fit = fit_func_1(del_centers, *fit_gauss_params)\n",
    "        fit_err = fit_error(heights, fit)\n",
    "\n",
    "        # See if an exponential decay tail exists and is a better fit\n",
    "\n",
    "        for i in range(peak_ind, len(centers)):\n",
    "\n",
    "            try:\n",
    "\n",
    "                v_T = centers[i]\n",
    "\n",
    "                exp_centers = del_centers[i:] - del_centers[i]\n",
    "\n",
    "                exp_heights = heights[i:]\n",
    "                init_height = exp_heights[0]\n",
    "\n",
    "                # Estimating alpha using half-life decay\n",
    "                alpha = 0\n",
    "\n",
    "                for j in range(0, len(exp_centers)):\n",
    "                    if(exp_heights[j] <= init_height/2):\n",
    "                        alpha = np.log(2)/(exp_centers[j])\n",
    "                        break\n",
    "\n",
    "                B = (fit_params[0]*np.exp(alpha*v_T))/np.sqrt(2*np.pi*fit_params[2]**2)*np.exp(-(v_T-mu)**2/(2*fit_params[2]**2))\n",
    "\n",
    "                guess_exp_params = np.array([B, alpha])\n",
    "                \n",
    "                exp_bounds = ([0, 0], [np.max(heights), np.inf])\n",
    "\n",
    "                fit_exp_params, fit_exp_covar = optimize.curve_fit(fit_func_2, exp_centers, exp_heights,\n",
    "                                                                   p0 = guess_exp_params, \n",
    "                                                                   bounds = exp_bounds, method = 'trf')\n",
    "\n",
    "                gauss_fit = fit_func_1(del_centers[:i], *fit_gauss_params)\n",
    "                exp_fit = fit_func_2(exp_centers, *fit_exp_params)\n",
    "                curr_fit = np.concatenate([gauss_fit, exp_fit])\n",
    "                curr_err = fit_error(heights, curr_fit)\n",
    "\n",
    "                if(curr_err < fit_err):\n",
    "                    fit = curr_fit\n",
    "                    fit_err = curr_err\n",
    "                    fit_params[3] = fit_exp_params[1]\n",
    "                    fit_params[4] = v_T\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    except:\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    return fit, fit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_snap(info):\n",
    "    \n",
    "    snap_dict = info[0]\n",
    "    metals = info[1]\n",
    "    spath_metals = info[2]\n",
    "    q = info[3]\n",
    "\n",
    "    snap = snap_dict['snap']\n",
    "    redshift = snap_dict['redshift']\n",
    "        \n",
    "    try:\n",
    "\n",
    "        A = {}\n",
    "        mu = {}\n",
    "        sigma = {}\n",
    "        alpha = {}\n",
    "        z_T = {}\n",
    "\n",
    "        for m in metals:\n",
    "\n",
    "            num_df = pd.read_csv(spath_metals[m] +'data/num/' + str(snap) + '-num_' + m + '_data.csv')\n",
    "\n",
    "            centers = np.array(num_df['abundance'].to_list())\n",
    "\n",
    "            heights = np.array(num_df['num_val'].to_list())\n",
    "\n",
    "            mass_norm = np.max(heights)\n",
    "\n",
    "            heights /= mass_norm\n",
    "\n",
    "            # Compute the fitted PDF\n",
    "\n",
    "            fit, fit_params = fit_PDF(centers, heights)\n",
    "\n",
    "            # Rescaling range to achieve desired normalization\n",
    "\n",
    "            heights *= mass_norm\n",
    "            fit *= mass_norm\n",
    "            fit_params[0] *= mass_norm\n",
    "\n",
    "            A[m] = fit_params[0]\n",
    "            mu[m] = fit_params[1]\n",
    "            sigma[m] = fit_params[2]\n",
    "            alpha[m] = fit_params[3]\n",
    "            z_T[m] = fit_params[4]\n",
    "\n",
    "            datafile =  str(snap) + '-fit_' + m + '_data' + '.csv'\n",
    "\n",
    "            fit_dict = {'abundance': centers, 'fit_val': fit}\n",
    "            fit_df = pd.DataFrame(fit_dict)\n",
    "            fit_df.to_csv(spath_metals[m] + 'data/fit/' + datafile, index = False)\n",
    "\n",
    "        q.put({'snap_dict': snap_dict, 'A': A, 'mu': mu, 'sigma': sigma, 'alpha': alpha, 'z_T': z_T})\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        for m in metals:\n",
    "            \n",
    "            datafile =  'fit_{}_params.csv'.format(m)\n",
    "            fit_df = pd.read_csv(spath_metals[m] + 'data/fit/' + datafile)\n",
    "            fit_df = fit_df[fit_df.snap != snap]\n",
    "            fit_df.to_csv(spath_metals[m] + 'data/fit/' + datafile, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter simulation directory path: /Users/thepoetoftwilight/Documents/CASSI2020/CASSI2020-Results/m10q_res250/\n"
     ]
    }
   ],
   "source": [
    "# Specifying simulation directory and the directory to save results in\n",
    "wdir = str(input('Enter simulation directory path: '))\n",
    "\n",
    "# Specifying a snapshot for temporal analysis\n",
    "sdir = wdir + 'temporal_analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rendered indices\n",
    "\n",
    "rendered_df = pd.read_csv(sdir + 'rendered_snap_stats.csv')\n",
    "snap_dicts = rendered_df.to_dict(orient = 'records')\n",
    "\n",
    "# Get rendered metals\n",
    "\n",
    "metal_df = pd.read_csv((sdir + 'metal_list.csv'))\n",
    "metals = metal_df['metals'].to_list()\n",
    "\n",
    "# Create a list of paths for all metals\n",
    "spath_metals = {}\n",
    "\n",
    "for m in metals:\n",
    "    spath_metals[m] = sdir + m + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to start:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:426: RuntimeWarning: invalid value encountered in subtract\n",
      "  upper_dist = ub - x\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:432: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (lower_dist <= np.minimum(upper_dist, lower_threshold)))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:426: RuntimeWarning: invalid value encountered in subtract\n",
      "  upper_dist = ub - x\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:436: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (upper_dist <= np.minimum(lower_dist, upper_threshold)))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:432: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (lower_dist <= np.minimum(upper_dist, lower_threshold)))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:436: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (upper_dist <= np.minimum(lower_dist, upper_threshold)))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in multiply\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in multiply\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:426: RuntimeWarning: invalid value encountered in subtract\n",
      "  upper_dist = ub - x\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:432: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (lower_dist <= np.minimum(upper_dist, lower_threshold)))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:436: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (upper_dist <= np.minimum(lower_dist, upper_threshold)))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in multiply\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:426: RuntimeWarning: invalid value encountered in subtract\n",
      "  upper_dist = ub - x\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:432: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (lower_dist <= np.minimum(upper_dist, lower_threshold)))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:436: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (upper_dist <= np.minimum(lower_dist, upper_threshold)))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in multiply\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:371: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return np.all((x >= lb) & (x <= ub))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:371: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return np.all((x >= lb) & (x <= ub))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:371: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return np.all((x >= lb) & (x <= ub))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:371: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return np.all((x >= lb) & (x <= ub))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:371: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return np.all((x >= lb) & (x <= ub))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:371: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return np.all((x >= lb) & (x <= ub))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:371: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return np.all((x >= lb) & (x <= ub))\n",
      "/Users/thepoetoftwilight/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_lsq/common.py:371: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return np.all((x >= lb) & (x <= ub))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     snap  redshift       time     halo_mass  SFR@10Myr  SFR@100Myr  \\\n",
      "0     110  3.266667   2.008803  2.786898e+09   0.001611    0.001169   \n",
      "1     111  3.238411   2.028696  2.959412e+09   0.008081    0.002210   \n",
      "2     112  3.210526   2.048648  3.048775e+09   0.015893    0.004517   \n",
      "3     113  3.183007   2.068659  3.119460e+09   0.007753    0.006225   \n",
      "4     114  3.155844   2.088728  3.178012e+09   0.006455    0.007100   \n",
      "..    ...       ...        ...           ...        ...         ...   \n",
      "447   596  0.000637  13.789874  8.534205e+09   0.000000    0.000000   \n",
      "448   597  0.000478  13.792092  8.534372e+09   0.000000    0.000000   \n",
      "449   598  0.000319  13.794310  8.534627e+09   0.000000    0.000000   \n",
      "450   599  0.000159  13.796529  8.534806e+09   0.000000    0.000000   \n",
      "451   600  0.000000  13.798747  8.534961e+09   0.000000    0.000000   \n",
      "\n",
      "     SFR@1000Myr  velocity_mass  velocity_vol  velocity_rms_mass  ...  \\\n",
      "0       0.001025      35.478512     55.402683          40.630207  ...   \n",
      "1       0.001153      34.682102     55.035786          39.941036  ...   \n",
      "2       0.001398      34.944656     55.220108          40.297947  ...   \n",
      "3       0.001576      35.643612     55.404831          41.139641  ...   \n",
      "4       0.001690      36.120785     55.445118          41.670254  ...   \n",
      "..           ...            ...           ...                ...  ...   \n",
      "447     0.000015      49.835361     85.839485          58.701008  ...   \n",
      "448     0.000015      49.844681     85.860893          58.713123  ...   \n",
      "449     0.000015      49.853504     85.881584          58.724854  ...   \n",
      "450     0.000015      49.862350     85.901939          58.736588  ...   \n",
      "451     0.000015      49.871212     85.921944          58.748245  ...   \n",
      "\n",
      "     thermal_mass  thermal_vol  thermal_rms_mass  thermal_rms_vol  \\\n",
      "0       22.308260    13.249514         23.626928        14.361768   \n",
      "1       22.287792    13.205904         23.691952        14.322658   \n",
      "2       22.317207    13.161935         24.054012        14.285146   \n",
      "3       22.418581    13.123489         24.650820        14.285446   \n",
      "4       22.595379    13.083987         25.123459        14.313667   \n",
      "..            ...          ...               ...              ...   \n",
      "447     11.189956     5.260764         12.448584         6.070414   \n",
      "448     11.190131     5.260725         12.450144         6.070395   \n",
      "449     11.189989     5.260706         12.449594         6.070371   \n",
      "450     11.190001     5.260668         12.449446         6.070344   \n",
      "451     11.189988     5.260654         12.449929         6.070322   \n",
      "\n",
      "     thermal_spread  mach_number_mass  mach_number_vol  mach_number_rms_mass  \\\n",
      "0          7.778346          2.792903         7.405939              3.949584   \n",
      "1          8.021189          2.767924         7.402691              4.030589   \n",
      "2          8.938107          2.816017         7.458961              4.419595   \n",
      "3         10.174247          2.905335         7.509007              5.190851   \n",
      "4         10.914400          2.871666         7.547110              4.604310   \n",
      "..              ...               ...              ...                   ...   \n",
      "447        5.448037          8.746697        33.098797             12.952761   \n",
      "448        5.451211          8.748596        33.107574             12.956372   \n",
      "449        5.450229          8.750390        33.116226             12.959894   \n",
      "450        5.449876          8.752182        33.124706             12.963362   \n",
      "451        5.450985          8.753934        33.132896             12.966715   \n",
      "\n",
      "     mach_number_rms_vol  mach_number_spread  \n",
      "0               9.217757            2.792228  \n",
      "1               9.217552            2.929073  \n",
      "2               9.290860            3.404239  \n",
      "3               9.355265            4.297533  \n",
      "4               9.407213            3.596163  \n",
      "..                   ...                 ...  \n",
      "447            42.478493            9.553976  \n",
      "448            42.491699            9.557156  \n",
      "449            42.504593            9.560285  \n",
      "450            42.517185            9.563339  \n",
      "451            42.529438            9.566284  \n",
      "\n",
      "[452 rows x 27 columns]\n",
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    n_proc = multiprocessing.cpu_count()\n",
    "    \n",
    "    print(\"About to start:\")\n",
    "    \n",
    "    manager = multiprocessing.Manager()\n",
    "    q = manager.Queue()\n",
    "\n",
    "    with Pool(processes = n_proc) as pool:\n",
    "\n",
    "        pool.map(fit_snap, [(snap_dict, metals, spath_metals, q) for snap_dict in snap_dicts])\n",
    "    \n",
    "    info_dicts = []\n",
    "    \n",
    "    while not q.empty():\n",
    "        info_dicts.append(q.get())\n",
    "      \n",
    "    rendered_dicts = []\n",
    "    A_dicts = []\n",
    "    mu_dicts = []\n",
    "    sigma_dicts = []\n",
    "    alpha_dicts = []\n",
    "    z_T_dicts = []\n",
    "    \n",
    "    for info_dict in info_dicts:\n",
    "        \n",
    "        rendered_dicts.append(info_dict['snap_dict'])\n",
    "        A_dicts.append(info_dict['A'])\n",
    "        mu_dicts.append(info_dict['mu'])\n",
    "        sigma_dicts.append(info_dict['sigma'])\n",
    "        alpha_dicts.append(info_dict['alpha'])\n",
    "        z_T_dicts.append(info_dict['z_T'])\n",
    "        \n",
    "    num_rendered_snaps = len(rendered_dicts)\n",
    "        \n",
    "    rendered_indices = []\n",
    "    redshifts = []\n",
    "    times = []\n",
    "\n",
    "    halo_masses = []\n",
    "\n",
    "    SFRs_10 = []\n",
    "    SFRs_100 = []\n",
    "    SFRs_1000 = []\n",
    "\n",
    "    velocities_mass = []\n",
    "    velocities_vol = []\n",
    "    velocities_rms_mass = []\n",
    "    velocities_rms_vol = []\n",
    "    velocities_spread = []\n",
    "\n",
    "    sounds_mass = []\n",
    "    sounds_vol = []\n",
    "    sounds_rms_mass = []\n",
    "    sounds_rms_vol = []\n",
    "    sounds_spread = []\n",
    "\n",
    "    thermals_mass = []\n",
    "    thermals_vol = []\n",
    "    thermals_rms_mass = []\n",
    "    thermals_rms_vol = []\n",
    "    thermals_spread = []\n",
    "\n",
    "    mach_numbers_mass = []\n",
    "    mach_numbers_vol = []\n",
    "    mach_numbers_rms_mass = []\n",
    "    mach_numbers_rms_vol = []\n",
    "    mach_numbers_spread = []\n",
    "\n",
    "    As = {}\n",
    "    mus = {}\n",
    "    sigmas = {}\n",
    "    alphas = {}\n",
    "    z_Ts = {}   \n",
    "    \n",
    "    for m in metals:\n",
    "        As[m] = []\n",
    "        mus[m] = []\n",
    "        sigmas[m] = []\n",
    "        alphas[m] = []\n",
    "        z_Ts[m] = []\n",
    "\n",
    "    for i in range(0, num_rendered_snaps):\n",
    "        \n",
    "        rendered_dict = rendered_dicts[i]\n",
    "        A_dict = A_dicts[i]\n",
    "        mu_dict = mu_dicts[i]\n",
    "        sigma_dict = sigma_dicts[i]\n",
    "        alpha_dict = alpha_dicts[i]\n",
    "        z_T_dict = alpha_dicts[i]\n",
    "        \n",
    "        rendered_indices.append(rendered_dict['snap'])\n",
    "        \n",
    "        redshifts.append(rendered_dict['redshift'])\n",
    "        times.append(rendered_dict['time'])\n",
    "        \n",
    "        halo_masses.append(rendered_dict['halo_mass'])\n",
    "        \n",
    "        SFRs_10.append(rendered_dict['SFR@10Myr'])\n",
    "        SFRs_100.append(rendered_dict['SFR@100Myr'])\n",
    "        SFRs_1000.append(rendered_dict['SFR@1000Myr'])\n",
    "\n",
    "        velocities_mass.append(rendered_dict['velocity_mass'])\n",
    "        velocities_vol.append(rendered_dict['velocity_vol'])\n",
    "        velocities_rms_mass.append(rendered_dict['velocity_rms_mass'])\n",
    "        velocities_rms_vol.append(rendered_dict['velocity_rms_vol'])\n",
    "        velocities_spread.append(rendered_dict['velocity_spread'])\n",
    "\n",
    "        sounds_mass.append(rendered_dict['sound_mass'])\n",
    "        sounds_vol.append(rendered_dict['sound_vol'])\n",
    "        sounds_rms_mass.append(rendered_dict['sound_rms_mass'])\n",
    "        sounds_rms_vol.append(rendered_dict['sound_rms_vol'])\n",
    "        sounds_spread.append(rendered_dict['sound_spread'])\n",
    "\n",
    "        thermals_mass.append(rendered_dict['thermal_mass'])\n",
    "        thermals_vol.append(rendered_dict['thermal_vol'])\n",
    "        thermals_rms_mass.append(rendered_dict['thermal_rms_mass'])\n",
    "        thermals_rms_vol.append(rendered_dict['thermal_rms_vol'])\n",
    "        thermals_spread.append(rendered_dict['thermal_spread'])\n",
    "\n",
    "        mach_numbers_mass.append(rendered_dict['mach_number_mass'])\n",
    "        mach_numbers_vol.append(rendered_dict['mach_number_vol'])\n",
    "        mach_numbers_rms_mass.append(rendered_dict['mach_number_rms_mass'])\n",
    "        mach_numbers_rms_vol.append(rendered_dict['mach_number_rms_vol'])\n",
    "        mach_numbers_spread.append(rendered_dict['mach_number_spread'])\n",
    "        \n",
    "        for m in metals:\n",
    "            \n",
    "            As[m].append(A_dict[m])\n",
    "            mus[m].append(mu_dict[m])\n",
    "            sigmas[m].append(sigma_dict[m])\n",
    "            alphas[m].append(alpha_dict[m])\n",
    "            z_Ts[m].append(z_T_dict[m])\n",
    "            \n",
    "    rendered_stats_dict = {'snap': rendered_indices,  'redshift': redshifts, 'time': times, \n",
    "                           'halo_mass': halo_masses,\n",
    "                           'SFR@10Myr': SFRs_10, 'SFR@100Myr': SFRs_100, 'SFR@1000Myr': SFRs_1000,\n",
    "                           'velocity_mass': velocities_mass, 'velocity_vol': velocities_vol, \n",
    "                           'velocity_rms_mass': velocities_rms_mass, 'velocity_rms_vol': velocities_rms_vol, \n",
    "                           'velocity_spread': velocities_spread,\n",
    "                           'sound_mass': sounds_mass, 'sound_vol': sounds_vol,\n",
    "                           'sound_rms_mass': sounds_rms_mass, 'sound_rms_vol': sounds_rms_vol,\n",
    "                           'sound_spread': sounds_spread,\n",
    "                           'thermal_mass': thermals_mass, 'thermal_vol': thermals_vol,\n",
    "                           'thermal_rms_mass': thermals_rms_mass, 'thermal_rms_vol': thermals_rms_vol,\n",
    "                           'thermal_spread': thermals_spread,\n",
    "                           'mach_number_mass': mach_numbers_mass, 'mach_number_vol': mach_numbers_vol,\n",
    "                           'mach_number_rms_mass': mach_numbers_rms_mass, \n",
    "                           'mach_number_rms_vol': mach_numbers_rms_vol, \n",
    "                           'mach_number_spread': mach_numbers_spread}\n",
    "\n",
    "    rendered_stats_df = pd.DataFrame(rendered_stats_dict)\n",
    "    rendered_stats_df = rendered_stats_df.sort_values(by = 'snap')\n",
    "    rendered_stats_df = rendered_stats_df.reset_index(drop = True)\n",
    "    rendered_stats_df.to_csv(sdir + 'rendered_snap_stats.csv', index = False)\n",
    "\n",
    "    print(rendered_stats_df)\n",
    "    print()\n",
    "\n",
    "    for m in metals:\n",
    "        param_df_init = pd.read_csv(spath_metals[m] + 'data/fit/fit_{}_params.csv'.format(m))\n",
    "        param_dict_append = {'A': As[m], 'mu': mus[m], 'sigma': sigmas[m], \n",
    "                      'alpha': alphas[m], 'z_T': z_Ts[m]}\n",
    "        param_df_append = pd.DataFrame(param_dict_append)\n",
    "        param_df = pd.concat([param_df_init, param_df_append], axis = 1)\n",
    "        param_df.to_csv(spath_metals[m] + 'data/fit/fit_{}_params.csv'.format(m), index = False)\n",
    "        \n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
